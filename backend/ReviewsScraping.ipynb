{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c312bab-59b5-4177-986d-1be91bf5875f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "def initialize_driver():\n",
    "    # Set up options for headless mode\n",
    "    options = Options()\n",
    "    options.add_argument(\"--headless\")  # Run in headless mode (no GUI)\n",
    "    options.add_argument(\"--disable-gpu\")  # Disable GPU (not needed in headless)\n",
    "    options.add_argument(\"--window-size=1920x1080\")  # Ensure proper viewport size\n",
    "\n",
    "    # Initialize WebDriver with the options\n",
    "    driver = webdriver.Chrome(ChromeDriverManager().install(), options=options)\n",
    "    return driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ffbf6e5-c714-49ea-a525-a267031fdfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to extract review link from product link\n",
    "def get_review_url(product_url):\n",
    "    # Extract product ID using regular expression (number before '/buy')\n",
    "    product_id_match = re.search(r'/(\\d+)/buy', product_url)\n",
    "    \n",
    "    if product_id_match:\n",
    "        product_id = product_id_match.group(1)\n",
    "        # Construct the review URL\n",
    "        review_url = f'https://www.myntra.com/reviews/{product_id}'\n",
    "        return review_url\n",
    "    else:\n",
    "        print(\"Invalid product URL. Could not extract product ID.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8033831-006f-44c6-bbd1-2d750584dc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scroll_and_scrape(driver, review_url, max_reviews=1000):\n",
    "    # Navigate to the review URL\n",
    "    driver.get(review_url)\n",
    "    \n",
    "    # Wait for the review elements to load\n",
    "    try:\n",
    "        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, 'user-review-reviewTextWrapper')))\n",
    "        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, 'user-review-starRating')))\n",
    "        time.sleep(2)\n",
    "    except Exception as e:\n",
    "        print(f\"Error while waiting for elements: {e}\")\n",
    "    \n",
    "    review_texts = []\n",
    "    star_ratings = []\n",
    "    \n",
    "    # Scroll until the reviews are loaded, or until the limit is reached\n",
    "    while len(review_texts) < max_reviews:\n",
    "        # Get the last review element\n",
    "        last_review = driver.find_elements(By.CLASS_NAME, 'user-review-reviewTextWrapper')[-1]\n",
    "        \n",
    "        # Scroll to the last review element\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView();\", last_review)\n",
    "        \n",
    "        # Wait for the new reviews to load (2 seconds)\n",
    "        time.sleep(2)\n",
    "\n",
    "        # Get the current page source and check for new reviews\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        reviews = soup.find_all('div', class_='user-review-reviewTextWrapper')\n",
    "        ratings = soup.find_all('span', class_='user-review-starRating')\n",
    "\n",
    "        # If no new reviews were loaded, stop scraping\n",
    "        if len(reviews) == len(review_texts):\n",
    "            print(\"No new reviews loaded. Stopping the scraping process.\")\n",
    "            break\n",
    "        \n",
    "        # Update review_texts and star_ratings with the new reviews\n",
    "        review_texts = [review.get_text(strip=True) for review in reviews]\n",
    "        star_ratings = [rating.get_text(strip=True) for rating in ratings]\n",
    "        \n",
    "        print(f\"Found {len(review_texts)} reviews. Scrolling again.\")\n",
    "    \n",
    "    # Ensure the reviews do not exceed max_reviews\n",
    "    review_texts = review_texts[:max_reviews]\n",
    "    star_ratings = star_ratings[:max_reviews]\n",
    "\n",
    "    return review_texts, star_ratings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3473d5c3-956d-49f6-a93d-e0e762c04977",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_reviews_from_product_url(product_url, max_reviews=1000):\n",
    "    # Extract the review URL from the product URL\n",
    "    review_url = get_review_url(product_url)\n",
    "    \n",
    "    if review_url is None:\n",
    "        return None, None\n",
    "    \n",
    "    # Start the WebDriver and scrape reviews\n",
    "    driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "    review_texts, star_ratings = scroll_and_scrape(driver, review_url, max_reviews)\n",
    "\n",
    "    # Handle mismatched data by adjusting\n",
    "    if len(review_texts) != len(star_ratings):\n",
    "        min_len = min(len(review_texts), len(star_ratings))\n",
    "        review_texts = review_texts[:min_len]\n",
    "        star_ratings = star_ratings[:min_len]\n",
    "        print(f\"Mismatched data: Adjusted to {min_len} reviews and ratings.\")\n",
    "    \n",
    "    # Create a DataFrame\n",
    "    data = {\n",
    "        'Review': review_texts,\n",
    "        'Stars': star_ratings\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Save the DataFrame to a CSV file\n",
    "    df.to_csv('myntra_reviews.csv', index=False)\n",
    "\n",
    "    # Close the browser\n",
    "    driver.quit()\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f1fb99d-def1-4733-85b9-543f6fd2e8c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zayan\\AppData\\Local\\Temp\\ipykernel_25396\\1584881633.py:9: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(ChromeDriverManager().install())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12 reviews. Scrolling again.\n",
      "Found 20 reviews. Scrolling again.\n",
      "Found 31 reviews. Scrolling again.\n",
      "Found 39 reviews. Scrolling again.\n",
      "Found 51 reviews. Scrolling again.\n",
      "Found 62 reviews. Scrolling again.\n",
      "Found 74 reviews. Scrolling again.\n",
      "Found 86 reviews. Scrolling again.\n",
      "Found 97 reviews. Scrolling again.\n",
      "Found 109 reviews. Scrolling again.\n",
      "Found 120 reviews. Scrolling again.\n",
      "Found 132 reviews. Scrolling again.\n",
      "Found 144 reviews. Scrolling again.\n",
      "Found 155 reviews. Scrolling again.\n",
      "Found 167 reviews. Scrolling again.\n",
      "Found 179 reviews. Scrolling again.\n",
      "Found 191 reviews. Scrolling again.\n",
      "Found 203 reviews. Scrolling again.\n",
      "Found 215 reviews. Scrolling again.\n",
      "Found 227 reviews. Scrolling again.\n",
      "Found 239 reviews. Scrolling again.\n",
      "Found 251 reviews. Scrolling again.\n",
      "Found 263 reviews. Scrolling again.\n",
      "Found 275 reviews. Scrolling again.\n",
      "Found 287 reviews. Scrolling again.\n",
      "Found 299 reviews. Scrolling again.\n",
      "Found 311 reviews. Scrolling again.\n",
      "Found 323 reviews. Scrolling again.\n",
      "Found 334 reviews. Scrolling again.\n",
      "Found 346 reviews. Scrolling again.\n",
      "Found 358 reviews. Scrolling again.\n",
      "No new reviews loaded. Stopping the scraping process.\n"
     ]
    }
   ],
   "source": [
    "product_url = 'https://www.myntra.com/tops/anouk/anouk-ethnic-printed-cuban-collar-pure-cotton-shirt-style-top/29958960/buy'\n",
    "df = scrape_reviews_from_product_url(product_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d3de5fb7-66e7-46ec-977e-9f0462333475",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I know how important it is for anyone buying d...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Really yaar 2 good</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I absolutely adore this crop shirt! I paired i...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Absolutely love this shirt! It fits perfectly ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It's a beautiful n a soothing  cotton short/cr...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review Stars\n",
       "0  I know how important it is for anyone buying d...     5\n",
       "1                                 Really yaar 2 good     5\n",
       "2  I absolutely adore this crop shirt! I paired i...     5\n",
       "3  Absolutely love this shirt! It fits perfectly ...     5\n",
       "4  It's a beautiful n a soothing  cotton short/cr...     4"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "707e8513-d150-4199-af8d-d73260bb852f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion complete: ReviewsScraping.py created.\n"
     ]
    }
   ],
   "source": [
    "import nbformat\n",
    "from nbconvert import PythonExporter\n",
    "\n",
    "# Load the notebook\n",
    "with open(\"linearSVM.ipynb\", \"r\", encoding=\"utf-8\") as f:\n",
    "    notebook = nbformat.read(f, as_version=4)\n",
    "\n",
    "# Convert to Python script\n",
    "exporter = PythonExporter()\n",
    "python_script, _ = exporter.from_notebook_node(notebook)\n",
    "\n",
    "# Save as .py file\n",
    "with open(\"linearSVM.py\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(python_script)\n",
    "\n",
    "print(\"Conversion complete: ReviewsScraping.py created.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bcb25b-ae5c-4f9e-a67f-7ca80805b5ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
